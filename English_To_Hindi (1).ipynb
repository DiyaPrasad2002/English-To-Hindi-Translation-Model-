{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f04aed-99d7-4b5f-b2d4-9d8c4ad725c0",
   "metadata": {},
   "source": [
    "## English To Hindi Translator Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5536e37-528d-4750-ba6f-f350e9b276ec",
   "metadata": {},
   "source": [
    "In the technically progressive era, scaling the capabilities of LLMs and LLM-based architectures, this project is an attempt to create an English to Hindi translator, by constructing an encoder-decoder architecture. \n",
    "\n",
    "#### Dataset : \n",
    "The dataset utilised was developed by IITB since 2016 at the Centre for Indian Language Technology, IITB. Different derivative corpus of the dataset are available, however, the dataset present on HuggingFace consists of 1,662,110 rows. Due to computational constraints, I have restricted my dataset to only 2500 rows, which consists of shuffled and mid to long sentences.\n",
    "\n",
    "#### Encoder-Decoder Model :\n",
    "Encoder-Decoder models are basically neural network architectures, making use of architectures like RNNs and LSTMs for tasks like machine translation. The encoder part of the architecture takes in the input sequence in one language, generates the context vector. The decoder accepts the context vector as an input and generates the desired output sequence, in the other language. \n",
    "\n",
    "#### Possibilities :\n",
    "Whilst I have restricted to the encoder-decoder architecture only, attention layers could be also added in the architecture to make the translator more context specific, thus progressing to more of a transformer-like architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "88e9ddf3-f862-4259-9f61-8d6789f5b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "5d49931c-bbeb-426d-9b71-7bbc306f7fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4183"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eae93d4-57c5-433d-88c7-dc82dd7baee9",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "c9ef4e1a-d644-44fb-a8bb-dc31fbb12129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "84b972ba-ab48-4d8c-a347-1433b9b0e2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import indian\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Input,Embedding, LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import string\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf42ee-80cb-4802-bbe6-645be95d3b48",
   "metadata": {},
   "source": [
    "### Analysing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "52721243-000d-444d-97c0-3fac4393cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('trans_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7394bece-d058-46ce-b9ca-ee125e3e9d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>13 . The person must be additional to your nor...</td>\n",
       "      <td>13 व्यक्ति आप के आम स्टॉफ की ज़रुरतों के अतिरि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>A river runs down through the valley.</td>\n",
       "      <td>वादी में से एक नदी बहती है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5777</th>\n",
       "      <td>If , after an enquiry , the Speaker is satisfi...</td>\n",
       "      <td>यदि जांच के पश्चात अध्यक्ष का समाधान हो जाता ह...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Don't say such a thing.</td>\n",
       "      <td>ऐसी बात मत बोलो।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>He walks his dog every morning.</td>\n",
       "      <td>वह हर सुबह अपने कुत्ते को सैर पर ले जाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                English  \\\n",
       "5882  13 . The person must be additional to your nor...   \n",
       "2094              A river runs down through the valley.   \n",
       "5777  If , after an enquiry , the Speaker is satisfi...   \n",
       "716                             Don't say such a thing.   \n",
       "1552                    He walks his dog every morning.   \n",
       "\n",
       "                                                  Hindi  \n",
       "5882  13 व्यक्ति आप के आम स्टॉफ की ज़रुरतों के अतिरि...  \n",
       "2094                        वादी में से एक नदी बहती है।  \n",
       "5777  यदि जांच के पश्चात अध्यक्ष का समाधान हो जाता ह...  \n",
       "716                                    ऐसी बात मत बोलो।  \n",
       "1552       वह हर सुबह अपने कुत्ते को सैर पर ले जाता है।  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "99590810-503d-4b29-a267-dbc1b40d4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.sample(2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "da3cf359-106c-46dd-b9d9-5e533b3d9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b18e9137-f131-4e5a-86e9-556027d14052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2500</td>\n",
       "      <td>2494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2470</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>(Laughter)</td>\n",
       "      <td>(हंसी)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           English   Hindi\n",
       "count         2500    2494\n",
       "unique        2470    2464\n",
       "top     (Laughter)  (हंसी)\n",
       "freq            10       5"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2b61b7b3-a817-41b3-8064-6f14989dbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2500 entries, 3779 to 5426\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   English  2500 non-null   object\n",
      " 1   Hindi    2494 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 58.6+ KB\n"
     ]
    }
   ],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "334fc899-7c07-48b0-ac18-3f691253c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24548500-bfac-451a-98da-ecc8dc605424",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "eb2e34f8-5897-4982-9fce-ee9443aabfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    if isinstance(text,str):\n",
    "        pattern = re.compile('<.*?>')\n",
    "        return pattern.sub(r'',text)\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "67cd8119-620b-47ea-b504-21378cdf977e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    if isinstance(text,str):\n",
    "        pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "        return pattern.sub(r'',text)\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f2f068c7-bc39-441c-8c02-f74b40bf2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, language='english'):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    if language == 'english':\n",
    "        pattern = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "        return pattern.sub(r'', text)\n",
    "    elif language == 'hindi':\n",
    "        pattern = re.compile(r'[^\\u0900-\\u097F\\s]')\n",
    "        return pattern.sub(r'', text)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported Language, Supported languages are 'english' and 'hindi'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "7b074400-cd35-44af-9913-5a78845c89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns = {'English' : 'english', 'Hindi' : 'hindi'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "4b402a53-e0fb-49f4-bf16-12371a9fad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['english'] = new_data['english'].apply(remove_html)\n",
    "new_data[\"hindi\"] = new_data[\"hindi\"].apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "02586868-e339-4f8f-b4d9-0a67fa84cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['english'] = new_data['english'].apply(remove_url)\n",
    "new_data[\"hindi\"] = new_data[\"hindi\"].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9afd91cc-d768-4d50-8ac9-9f201fcae604",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['english'] = new_data['english'].apply(lambda x: preprocess_text(x, language='english'))\n",
    "new_data['hindi'] = new_data['hindi'].apply(lambda x: preprocess_text(x, language='hindi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "55e664ab-10cf-4b87-92e6-cde0ee1bed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "e995c9f2-3021-4441-9890-1f79cb44f8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hindi_punctuations():\n",
    "    hindi_punctuations = []\n",
    "    for i in range(0x2000, 0x206f + 1):\n",
    "        char = chr(i)\n",
    "        if unicodedata.category(char) == 'Po':\n",
    "            hindi_punctuations.append(char)\n",
    "    return ''.join(hindi_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "871efafb-cf94-4dc7-8196-56099b9d32b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindi_punctuation = get_hindi_punctuations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "fbe27f0b-2b11-4f96-a8d9-4662d9324d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‖‗†‡•‣․‥…‧‰‱′″‴‵‶‷‸※‼‽‾⁁⁂⁃⁇⁈⁉⁊⁋⁌⁍⁎⁏⁐⁑⁓⁕⁖⁗⁘⁙⁚⁛⁜⁝⁞'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "4020f5e4-8e0f-4287-ac5b-1aadaf72c6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text, language = 'english'):\n",
    "    if language == 'english':\n",
    "        exclude_english = set(string.punctuation)\n",
    "        return ''.join(char for char in text if char not in exclude_english)\n",
    "    elif language == 'hindi':\n",
    "        return ''.join(char for char in text if char not in hindi_punctuation)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported Language, Supported languages are 'english' and 'hindi'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "70772552-c19f-4c6e-aeed-d406d6dde80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['english'] = new_data['english'].apply(lambda x: remove_punctuation(x,language = 'english'))\n",
    "new_data['hindi'] = new_data['hindi'].apply(lambda x: remove_punctuation(x,language = 'hindi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "53660111-1429-47e5-b1ed-ee59740b5696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    expanded_text = contractions.fix(text)\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "dfa979b2-a62b-484e-844b-dbcfd068c541",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data[\"english\"] = new_data[\"english\"].apply(expand_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "68140788-d75c-471e-860c-6d61fe4587c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>But the difficulties in the way of modernisati...</td>\n",
       "      <td>लेकिन आधुनिकीकरण करने में भी अनेक बाधाएं थीं ज...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>His lack of political ambition also makes it e...</td>\n",
       "      <td>उनमें राजनैतिक महत्वाकांक्षाएं न होना भी युद्ध...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Do Not open your book</td>\n",
       "      <td>अपनी किताब मत खोलो।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9398</th>\n",
       "      <td>In the year 712 Mohammad Bin Kasim the command...</td>\n",
       "      <td>सन्  में फारस के सेनापति मुहम्मद बिन क़ासिम ने...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>Akkamahadevi came to Kalyana and met people in...</td>\n",
       "      <td>अक़्कमहादेवी कल्याण पहुंची तथा बसव के घर में ल...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                english  \\\n",
       "4921  But the difficulties in the way of modernisati...   \n",
       "4054  His lack of political ambition also makes it e...   \n",
       "522                               Do Not open your book   \n",
       "9398  In the year 712 Mohammad Bin Kasim the command...   \n",
       "4587  Akkamahadevi came to Kalyana and met people in...   \n",
       "\n",
       "                                                  hindi  \n",
       "4921  लेकिन आधुनिकीकरण करने में भी अनेक बाधाएं थीं ज...  \n",
       "4054  उनमें राजनैतिक महत्वाकांक्षाएं न होना भी युद्ध...  \n",
       "522                                 अपनी किताब मत खोलो।  \n",
       "9398  सन्  में फारस के सेनापति मुहम्मद बिन क़ासिम ने...  \n",
       "4587  अक़्कमहादेवी कल्याण पहुंची तथा बसव के घर में ल...  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ab26a-3a1e-452a-bc88-692867a35a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d935f387-0a78-4b20-842b-4964acbb856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['hindi'] = new_data['hindi'].apply(lambda x : 'start_ ' + x + ' _end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6a641134-a623-43aa-9ffa-93cf42d1d99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>When the headlines rolled what happened was</td>\n",
       "      <td>start_ जब सुर्खियों में आती हैतो क्या होता है ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>Everyone could easily see his disappointment</td>\n",
       "      <td>start_ उसकी निराशा सभी आसानी से दिख सकते थे। _end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>We may not win tomorrow</td>\n",
       "      <td>start_ हम कल शायद नहीं जीतेंगे। _end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           english  \\\n",
       "4609   When the headlines rolled what happened was   \n",
       "2520  Everyone could easily see his disappointment   \n",
       "879                        We may not win tomorrow   \n",
       "\n",
       "                                                  hindi  \n",
       "4609  start_ जब सुर्खियों में आती हैतो क्या होता है ...  \n",
       "2520  start_ उसकी निराशा सभी आसानी से दिख सकते थे। _end  \n",
       "879                start_ हम कल शायद नहीं जीतेंगे। _end  "
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e183100-66f9-4676-b9e1-a57420187a65",
   "metadata": {},
   "source": [
    "### Dictionary and Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "18a1793b-c2b9-4451-b509-cd8660694da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = set()\n",
    "hindi_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "73c545e3-9ad3-4178-89b5-900506375680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for eng in new_data['english']:\n",
    "    for word in eng.split():\n",
    "        if word not in eng_words:\n",
    "            eng_words.add(word)\n",
    "\n",
    "for hindi in new_data['hindi']:\n",
    "    for word in hindi.split():\n",
    "        if word not in hindi_words:\n",
    "            hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "1249c6c1-f37f-4f95-a7f2-41479fa7157c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'partymen',\n",
       " 'attributes',\n",
       " 'Reporting',\n",
       " 'Pakistan',\n",
       " 'wrinkles',\n",
       " 'utensils',\n",
       " 'transport',\n",
       " 'spines',\n",
       " 'fourth',\n",
       " 'Sanders',\n",
       " 'stubborn',\n",
       " 'likely',\n",
       " 'RamakrishnaVivekananda',\n",
       " 'trail',\n",
       " 'metric',\n",
       " 'shade',\n",
       " 'wonders',\n",
       " 'farmers',\n",
       " 'scare',\n",
       " 'them',\n",
       " '1945',\n",
       " 'negatived',\n",
       " 'idoltemple',\n",
       " 'declare',\n",
       " 'young',\n",
       " 'counsel',\n",
       " 'As',\n",
       " 'wall',\n",
       " 'Bharata',\n",
       " 'process',\n",
       " 'Surdas',\n",
       " 'maintain',\n",
       " 'joke',\n",
       " 'disappointed',\n",
       " 'prefer',\n",
       " 'stop',\n",
       " 'Mohan',\n",
       " 'transliteration',\n",
       " 'leading',\n",
       " 'extension',\n",
       " 'lotteries',\n",
       " 'Satyajit',\n",
       " 'Resignation',\n",
       " 'Age',\n",
       " 'uncle',\n",
       " 'Elysium',\n",
       " 'range',\n",
       " '261',\n",
       " 'Please',\n",
       " 'talk',\n",
       " 'Adhirath',\n",
       " 'organize',\n",
       " 'Allahabad',\n",
       " 'starting',\n",
       " 'Legislative',\n",
       " 'rewards',\n",
       " 'interests',\n",
       " 'idiom',\n",
       " 'Bahadur',\n",
       " 'passing',\n",
       " 'Birds',\n",
       " 'legislative',\n",
       " 'Simla',\n",
       " 'travel',\n",
       " 'wisdom',\n",
       " 'prime',\n",
       " 'decribe',\n",
       " 'arches',\n",
       " 'commtment',\n",
       " 'then',\n",
       " 'V',\n",
       " 'wave',\n",
       " 'magnify',\n",
       " 'acquiring',\n",
       " 'considerations',\n",
       " 'Premchand',\n",
       " 'Tudi',\n",
       " 'before',\n",
       " 'IF',\n",
       " 'farm',\n",
       " 'notions',\n",
       " 'nothing',\n",
       " 'coordinating',\n",
       " 'bronze',\n",
       " 'imposed',\n",
       " 'reckon',\n",
       " 'association',\n",
       " 'Dhariwal',\n",
       " 'announcement',\n",
       " 'store',\n",
       " 'jajiya',\n",
       " 'Applications',\n",
       " 'How',\n",
       " 'Garden',\n",
       " 'race',\n",
       " 'Who',\n",
       " 'associated',\n",
       " 'Doctor',\n",
       " 'core',\n",
       " 'classical',\n",
       " 'centre',\n",
       " 'Taj',\n",
       " 'authorities',\n",
       " 'half',\n",
       " 'course',\n",
       " '1995',\n",
       " 'myself',\n",
       " 'Making',\n",
       " 'point',\n",
       " 'pulling',\n",
       " 'attacks',\n",
       " 'Pakistanbased',\n",
       " 'illegally',\n",
       " 'justified',\n",
       " 'alien',\n",
       " 'Committee',\n",
       " 'referencing',\n",
       " 'transmission',\n",
       " 'anxious',\n",
       " 'liked',\n",
       " 'Antarctica',\n",
       " 'planet',\n",
       " 'element',\n",
       " 'discharged',\n",
       " 'Martin',\n",
       " 'dense',\n",
       " 'only',\n",
       " 'crying',\n",
       " 'organiser',\n",
       " 'alltime',\n",
       " 'hostile',\n",
       " 'forever',\n",
       " '200',\n",
       " 'newly',\n",
       " 'US',\n",
       " 'field',\n",
       " 'organised',\n",
       " 'poorest',\n",
       " 'art',\n",
       " 'complex',\n",
       " 'whether',\n",
       " 'obtain',\n",
       " 'we',\n",
       " 'Spring',\n",
       " 'BARs',\n",
       " 'guarding',\n",
       " 'clear',\n",
       " 'Cup',\n",
       " 'trouble',\n",
       " 'Lignite',\n",
       " 'possibilities',\n",
       " 'warning',\n",
       " 'Ayoob',\n",
       " 'deeply',\n",
       " 'matter',\n",
       " 'federation',\n",
       " 'misfortune',\n",
       " 'Buddha',\n",
       " 'Hindustani',\n",
       " 'untapped',\n",
       " 'blocked',\n",
       " 'headed',\n",
       " 'immortality',\n",
       " 'Among',\n",
       " '21870',\n",
       " 'Sut',\n",
       " 'decipher',\n",
       " 'walked',\n",
       " 'operator',\n",
       " 'precious',\n",
       " 'pur',\n",
       " 'Monotheism',\n",
       " 'growers',\n",
       " 'Fisheries',\n",
       " 'HEC',\n",
       " 'teenagers',\n",
       " 'On',\n",
       " 'Higher',\n",
       " 'Kakotta',\n",
       " 'jajia',\n",
       " 'Prior',\n",
       " 'easiest',\n",
       " 'venture',\n",
       " 'cap',\n",
       " 'Saheb',\n",
       " 'liberation',\n",
       " 'stages',\n",
       " 'AmericaAfrica',\n",
       " 'robbing',\n",
       " 'presence',\n",
       " 'mover',\n",
       " 'Cotton',\n",
       " 'reproducing',\n",
       " 'inferring',\n",
       " 'worried',\n",
       " 'places',\n",
       " 'conventional',\n",
       " 'embrace',\n",
       " 'covers',\n",
       " 'becomes',\n",
       " 'fine',\n",
       " 'experiments',\n",
       " 'signal',\n",
       " 'dabbled',\n",
       " 'architect',\n",
       " 'waving',\n",
       " 'observed',\n",
       " 'Martial',\n",
       " 'consideration',\n",
       " 'February',\n",
       " 'multimedia',\n",
       " 'information',\n",
       " 'Maharashtra',\n",
       " 'riding',\n",
       " 'affairs',\n",
       " 'site',\n",
       " 'wings',\n",
       " 'botanical',\n",
       " 'identified',\n",
       " 'Survey',\n",
       " 'DPC',\n",
       " 'powers',\n",
       " 'typewriter',\n",
       " 'halt',\n",
       " 'selfdetermination',\n",
       " 'locus',\n",
       " 'Ophelia',\n",
       " 'scissors',\n",
       " 'gums',\n",
       " 'harvesting',\n",
       " 'Gupta',\n",
       " 'limitations',\n",
       " 'Ghose',\n",
       " 'powerful',\n",
       " 'say',\n",
       " 'wears',\n",
       " 'Jew',\n",
       " 'Reeti',\n",
       " 'supplied',\n",
       " 'Kesri',\n",
       " 'touch',\n",
       " 'PanchaPandava',\n",
       " 'Q',\n",
       " 'Charioteer',\n",
       " 'late',\n",
       " 'yesterday',\n",
       " 'recharged',\n",
       " 'eggs',\n",
       " 'bheemghoda',\n",
       " 'supposing',\n",
       " 'indigenous',\n",
       " 'woman',\n",
       " 'Governor',\n",
       " 'dialogue',\n",
       " 'Naldhamayanthi',\n",
       " 'speedy',\n",
       " 'stars',\n",
       " 'enigmatic',\n",
       " 'employed',\n",
       " 'put',\n",
       " 'Like',\n",
       " 'acrid',\n",
       " 'recall',\n",
       " 'raging',\n",
       " 'Devaswom',\n",
       " 'hero',\n",
       " 'gain',\n",
       " 'Imli',\n",
       " 'earned',\n",
       " 'adopting',\n",
       " 'ecologically',\n",
       " 'overdoor',\n",
       " 'several',\n",
       " 'sizes',\n",
       " 'twenty20',\n",
       " 'BICP',\n",
       " 'Wiktionary',\n",
       " 'padas',\n",
       " 'benefit',\n",
       " 'whoredom',\n",
       " 'had',\n",
       " 'CNN',\n",
       " 'summary',\n",
       " 'waiting',\n",
       " 'Continent',\n",
       " 'literally',\n",
       " 'RIGHT',\n",
       " 'everything',\n",
       " 'chart',\n",
       " 'Men',\n",
       " 'generous',\n",
       " 'sums',\n",
       " 'color',\n",
       " 'adaptation',\n",
       " 'guest',\n",
       " 'orthography',\n",
       " 'wicketkeeper',\n",
       " 'saying',\n",
       " 'cold',\n",
       " 'receded',\n",
       " 'instances',\n",
       " 'proceeds',\n",
       " 'father',\n",
       " 'retainers',\n",
       " 'T',\n",
       " 'memory',\n",
       " 'crowded',\n",
       " 'Genuine',\n",
       " 'eating',\n",
       " 'knee',\n",
       " 'recesses',\n",
       " 'card',\n",
       " 'Gothic',\n",
       " 'weeks',\n",
       " 'cars',\n",
       " 'leaves',\n",
       " 'dam',\n",
       " 'chariots',\n",
       " 'character',\n",
       " 'Marxism',\n",
       " 'desirable',\n",
       " 'Kaizen',\n",
       " 'allowances',\n",
       " 'metal',\n",
       " 'cover',\n",
       " 'detector',\n",
       " 'assure',\n",
       " 'Aging',\n",
       " 'cells',\n",
       " 'list',\n",
       " 'Whatan',\n",
       " 'Sunday',\n",
       " 'dollars',\n",
       " 'grateful',\n",
       " 'slightest',\n",
       " 'Feed',\n",
       " 'contains',\n",
       " 'accept',\n",
       " 'knack',\n",
       " 'mindset',\n",
       " '141987',\n",
       " 'poems',\n",
       " 'fielders',\n",
       " 'Gupt',\n",
       " 'limited',\n",
       " 'novel',\n",
       " 'Ayurveda',\n",
       " 'bullies',\n",
       " 'married',\n",
       " 'herself',\n",
       " 'memorable',\n",
       " 'glacial',\n",
       " 'gazed',\n",
       " 'two',\n",
       " 'composed',\n",
       " 'sapphires',\n",
       " 'happen',\n",
       " 'deadand',\n",
       " 'day',\n",
       " 'Terminus',\n",
       " 'ON',\n",
       " 'Hoysalas',\n",
       " 'CategorySanskrit',\n",
       " 'daily',\n",
       " 'chain',\n",
       " 'commentators',\n",
       " 'observing',\n",
       " 'enemy',\n",
       " 'franchisees',\n",
       " 'widening',\n",
       " 'beach',\n",
       " 'Judge',\n",
       " 'Bernard',\n",
       " 'Speech',\n",
       " 'lamps',\n",
       " 'snow',\n",
       " 'hospital',\n",
       " 'Book',\n",
       " 'flexible',\n",
       " 'spit',\n",
       " 'Topic',\n",
       " 'soothe',\n",
       " 'howling',\n",
       " 'scary',\n",
       " 'dung',\n",
       " 'Stephen',\n",
       " 'independently',\n",
       " 'Baroda',\n",
       " 'Marthahalli',\n",
       " 'sentences',\n",
       " 'enjoyed',\n",
       " 'Music',\n",
       " 'uses',\n",
       " 'troubles',\n",
       " 'cow',\n",
       " 'realm',\n",
       " 'mostly',\n",
       " 'demand',\n",
       " 'squirrel',\n",
       " 'perpetrated',\n",
       " 'handlooms',\n",
       " 'Vinayadhara',\n",
       " 'Kuru',\n",
       " 'welldeveloped',\n",
       " 'flowers',\n",
       " 'intervening',\n",
       " 'explosiion',\n",
       " 'harbinger',\n",
       " 'Seeing',\n",
       " 'FEV1',\n",
       " 'cocoanut',\n",
       " 'worthy',\n",
       " 'outlet',\n",
       " 'asusally',\n",
       " 'Hinduism',\n",
       " 'identifies',\n",
       " 'recharge',\n",
       " 'cartoonist',\n",
       " 'ft',\n",
       " 'effluents',\n",
       " 'Preamble',\n",
       " 'propagation',\n",
       " 'pinching',\n",
       " 'knew',\n",
       " 'plants',\n",
       " 'waking',\n",
       " 'helped',\n",
       " 'Intercracies',\n",
       " 'shrines',\n",
       " 'Bhushan',\n",
       " 'Delhi',\n",
       " 'taking',\n",
       " 'make',\n",
       " 'dress',\n",
       " 'blamed',\n",
       " 'imprisoned',\n",
       " 'interestingly',\n",
       " 'till',\n",
       " 'project',\n",
       " 'apply',\n",
       " 'defense',\n",
       " 'Asia',\n",
       " 'wound',\n",
       " 'machinery',\n",
       " 'remember',\n",
       " 'distancing',\n",
       " 'cheap',\n",
       " 'images',\n",
       " 'Veda',\n",
       " 'Harsha',\n",
       " 'hat',\n",
       " 'consultations',\n",
       " 'brain',\n",
       " 'indications',\n",
       " 'lying',\n",
       " 'Tripuri',\n",
       " 'sprays',\n",
       " 'post',\n",
       " 'ruthlessly',\n",
       " 'surveys',\n",
       " 'title',\n",
       " 'accusing',\n",
       " 'curious',\n",
       " 'Comintern',\n",
       " 'cash',\n",
       " 'tributes',\n",
       " 'DepthOnkar',\n",
       " 'sugar',\n",
       " 'ad',\n",
       " 'rights',\n",
       " 'comparatively',\n",
       " 'strikes',\n",
       " 'official',\n",
       " '04',\n",
       " 'Vaivart',\n",
       " 'Nabalig',\n",
       " 'Nonveg',\n",
       " 'reminiscent',\n",
       " 'fulfilled',\n",
       " 'just',\n",
       " 'pickpocketing',\n",
       " 'Orient',\n",
       " 'worst',\n",
       " 'uncover',\n",
       " 'news',\n",
       " 'much',\n",
       " 'surfridden',\n",
       " 'mega',\n",
       " 'Red',\n",
       " 'tallest',\n",
       " 'folder',\n",
       " 'game',\n",
       " 'careful',\n",
       " 'ml',\n",
       " 'mandapam',\n",
       " 'Capt',\n",
       " 'Applause',\n",
       " 'soon',\n",
       " 'family',\n",
       " 'persuaded',\n",
       " 'weeping',\n",
       " 'Beijing',\n",
       " 'scale',\n",
       " 'Hindikunj',\n",
       " 'monument',\n",
       " 'pair',\n",
       " 'fibrosis',\n",
       " 'Various',\n",
       " 'clans',\n",
       " 'constitution',\n",
       " 'downs',\n",
       " 'everyone',\n",
       " 'School',\n",
       " 'voice',\n",
       " 'solicitude',\n",
       " 'collect',\n",
       " '4000mile',\n",
       " 'nonmusical',\n",
       " 'thievery',\n",
       " '1986',\n",
       " 'Commission',\n",
       " 'gather',\n",
       " 'wartime',\n",
       " 'lesson',\n",
       " 'single',\n",
       " 'organise',\n",
       " 'eighth',\n",
       " 'problems',\n",
       " 'duty',\n",
       " 'fame',\n",
       " 'multicellular',\n",
       " 'North',\n",
       " 'turns',\n",
       " 'funny',\n",
       " 'AfghanSuba',\n",
       " 'happened',\n",
       " 'personality',\n",
       " 'May',\n",
       " 'door',\n",
       " 'batman',\n",
       " 'Thoughts',\n",
       " 'imperils',\n",
       " 'obstruction',\n",
       " 'grooves',\n",
       " 'labor',\n",
       " 'writing',\n",
       " 'Inspection',\n",
       " 'recommended',\n",
       " 'Dragon',\n",
       " 'ambulance',\n",
       " 'outgrown',\n",
       " '90It',\n",
       " 'tipping',\n",
       " 'Learning',\n",
       " 'TO',\n",
       " 'oakeroaks',\n",
       " 'thoughts',\n",
       " 'money',\n",
       " 'forceful',\n",
       " 'themselves',\n",
       " 'database',\n",
       " 'withered',\n",
       " 'target',\n",
       " 'IPS',\n",
       " 'Thank',\n",
       " 'products',\n",
       " 'excavated',\n",
       " 'deep',\n",
       " 'delivery',\n",
       " 'TH',\n",
       " 'although',\n",
       " 'seething',\n",
       " 'really',\n",
       " 'chromosomes',\n",
       " 'wait',\n",
       " '4400',\n",
       " 'essential',\n",
       " 'ATTUC',\n",
       " 'purpose',\n",
       " 'Line',\n",
       " 'approximately',\n",
       " 'selling',\n",
       " 'Vishnu',\n",
       " 'remove',\n",
       " 'Lynn',\n",
       " 'party',\n",
       " 'woollen',\n",
       " 'evidence',\n",
       " 'babyloanonline',\n",
       " 'homes',\n",
       " 'adoration',\n",
       " 'metro',\n",
       " 'increase',\n",
       " 'monotheism',\n",
       " 'remedies',\n",
       " 'democracy',\n",
       " 'ball',\n",
       " 'quorum',\n",
       " 'map',\n",
       " 'blows',\n",
       " 'level',\n",
       " 'carriers',\n",
       " '1934',\n",
       " 'ten',\n",
       " 'Funds',\n",
       " '302',\n",
       " 'Rr',\n",
       " 'returned',\n",
       " 'legislation',\n",
       " 'children',\n",
       " 'Kapadia',\n",
       " 'borrowed',\n",
       " 'test',\n",
       " 'aspects',\n",
       " 'Magnetic',\n",
       " 'wonderful',\n",
       " 'donates',\n",
       " 'Gandhi',\n",
       " 'Cristian',\n",
       " 'hygiene',\n",
       " 'assumption',\n",
       " 'struggle',\n",
       " 'rivermouths',\n",
       " 'insight',\n",
       " 'waters',\n",
       " 'clock',\n",
       " 'devtas',\n",
       " 'battingthat',\n",
       " 'furthering',\n",
       " 'dances',\n",
       " 'spell',\n",
       " '5',\n",
       " 'hungry',\n",
       " 'matches',\n",
       " 'consult',\n",
       " 'govt',\n",
       " '1971',\n",
       " 'friendly',\n",
       " 'open',\n",
       " '7',\n",
       " 'Lohadi',\n",
       " 'corruption',\n",
       " 'reading',\n",
       " 'sedition',\n",
       " 'faces',\n",
       " 'kms',\n",
       " 'Breasted',\n",
       " 'INDIA',\n",
       " 'widely',\n",
       " 'spreading',\n",
       " 'evict',\n",
       " '1952',\n",
       " 'eds',\n",
       " 'Representatives',\n",
       " 'seer',\n",
       " 'Madras',\n",
       " 'minute',\n",
       " 'least',\n",
       " 'played',\n",
       " 'Langman1999',\n",
       " 'ratha',\n",
       " 'professions',\n",
       " 'pulse',\n",
       " 'indirectly',\n",
       " 'wherever',\n",
       " 'bowler',\n",
       " 'positive',\n",
       " 'created',\n",
       " 'manifest',\n",
       " 'airyfairy',\n",
       " 'commercial',\n",
       " 'spraying',\n",
       " 'helps',\n",
       " 'DNA',\n",
       " 'You',\n",
       " 'withdrawn',\n",
       " 'France',\n",
       " 'SC',\n",
       " 'John',\n",
       " 'police',\n",
       " 'hepatitis',\n",
       " 'remedy',\n",
       " 'intimate',\n",
       " 'rays',\n",
       " 'outif',\n",
       " 'hostility',\n",
       " 'initially',\n",
       " 'tawa',\n",
       " 'Australia',\n",
       " 'consists',\n",
       " 'anticipating',\n",
       " 'focusing',\n",
       " 'additional',\n",
       " 'THE',\n",
       " 'Insist',\n",
       " 'proud',\n",
       " 'hesitation',\n",
       " 'dry',\n",
       " 'environment',\n",
       " 'verandah',\n",
       " 'compactness',\n",
       " 'sent',\n",
       " 'abuse',\n",
       " 'Sahadev',\n",
       " 'possession',\n",
       " 'investigate',\n",
       " 'constitute',\n",
       " '1613',\n",
       " 'secured',\n",
       " 'teacher',\n",
       " 'cell',\n",
       " 'childmind',\n",
       " 'automatic',\n",
       " 'complexity',\n",
       " 'delivered',\n",
       " 'penetrating',\n",
       " '8325',\n",
       " 'page',\n",
       " 'Religious',\n",
       " 'male',\n",
       " 'pleasure',\n",
       " 'activity',\n",
       " 'rips',\n",
       " 'completing',\n",
       " 'expansion',\n",
       " 'selfdriving',\n",
       " 'arguing',\n",
       " 'Bhojpuri',\n",
       " 'gas',\n",
       " 'plain',\n",
       " 'Navbharat',\n",
       " 'imagination',\n",
       " 'effect',\n",
       " 'returns',\n",
       " 'sikhara',\n",
       " '1857',\n",
       " 'exploiting',\n",
       " 'frequent',\n",
       " 'renewing',\n",
       " 'Abstract',\n",
       " 'ministry',\n",
       " 'Structure',\n",
       " 'junior',\n",
       " 'rubbish',\n",
       " 'anal',\n",
       " 'Exchange',\n",
       " 'love',\n",
       " 'symbols',\n",
       " 'princely',\n",
       " '40000',\n",
       " 'cool',\n",
       " 'procedures',\n",
       " 'could',\n",
       " 'five',\n",
       " 'Acsbieen',\n",
       " 'someone',\n",
       " '91st',\n",
       " 'computer',\n",
       " 'adaptability',\n",
       " 'rather',\n",
       " 'ideological',\n",
       " 'spoke',\n",
       " 'hours',\n",
       " 'appoint',\n",
       " 'African',\n",
       " 'mix',\n",
       " 'soldier',\n",
       " 'engine',\n",
       " 'walking',\n",
       " 'fifty',\n",
       " 'Ghaziabad',\n",
       " 'route',\n",
       " 'length',\n",
       " 'Subash',\n",
       " 'lines',\n",
       " 'presiding',\n",
       " 'ghatak',\n",
       " 'great',\n",
       " 'dangers',\n",
       " 'praise',\n",
       " 'cry',\n",
       " 'bite',\n",
       " 'folly',\n",
       " 'Hatia',\n",
       " 'explanation',\n",
       " 'bicycle',\n",
       " 'Kaal',\n",
       " 'create',\n",
       " 'branches',\n",
       " 'indication',\n",
       " 'street',\n",
       " 'ecologicallyresponsible',\n",
       " 'wildlife',\n",
       " 'oath',\n",
       " 'signing',\n",
       " 'palace',\n",
       " 'disposal',\n",
       " 'Indian',\n",
       " 'inmates',\n",
       " 'Master',\n",
       " 'advertising',\n",
       " 'Excuse',\n",
       " 'ever',\n",
       " 'Dhuryodhans',\n",
       " 'brilliance',\n",
       " 'Phanindra',\n",
       " 'territory',\n",
       " 'emperor',\n",
       " 'approaches',\n",
       " 'pumped',\n",
       " 'Guru',\n",
       " 'unauthorised',\n",
       " 'little',\n",
       " 'anniversary',\n",
       " 'proportionate',\n",
       " 'separtism',\n",
       " 'thanked',\n",
       " 'kid',\n",
       " 'throughout',\n",
       " 'friend',\n",
       " 'dependent',\n",
       " 'continent',\n",
       " 'Czech',\n",
       " 'Koneri',\n",
       " 'mining',\n",
       " 'aristocracy',\n",
       " 'weekly',\n",
       " 'indicates',\n",
       " 'seemingly',\n",
       " 'Third',\n",
       " 'Everest',\n",
       " 'catching',\n",
       " 'murderer',\n",
       " 'fifteen',\n",
       " 'pull',\n",
       " 'Text',\n",
       " 'NonAlignment',\n",
       " 'deterioration',\n",
       " 'frontier',\n",
       " 'turn',\n",
       " 'promoted',\n",
       " 'Poona',\n",
       " 'HE',\n",
       " 'Industrial',\n",
       " 'industry',\n",
       " 'Individuals',\n",
       " 'builders',\n",
       " '022',\n",
       " 'answered',\n",
       " 'superintendent',\n",
       " 'somewhat',\n",
       " 'To',\n",
       " 'Fullers',\n",
       " 'Document',\n",
       " 'Earth',\n",
       " 'Mahishamardini',\n",
       " 'Yagaya',\n",
       " 'Dmakudha',\n",
       " 'Huston',\n",
       " 'application',\n",
       " 'sheath',\n",
       " 'early',\n",
       " 'Check',\n",
       " 'Azamgarh',\n",
       " 'Part',\n",
       " '3billion',\n",
       " 'cringe',\n",
       " 'putting',\n",
       " 'devastation',\n",
       " '116',\n",
       " 'eight',\n",
       " 'Mumtaz',\n",
       " 'fluid',\n",
       " 'vimana',\n",
       " '1853',\n",
       " 'approach',\n",
       " 'genius',\n",
       " 'control',\n",
       " 'spend',\n",
       " 'loose',\n",
       " 'wronged',\n",
       " 'Regulation',\n",
       " 'propose',\n",
       " 'mutilated',\n",
       " 'poemwhich',\n",
       " 'climbed',\n",
       " 'Thames',\n",
       " 'victory',\n",
       " '1862',\n",
       " 'Diseases',\n",
       " 'dare',\n",
       " 'locally',\n",
       " 'volume',\n",
       " 'twin',\n",
       " 'treaty',\n",
       " 'concludes',\n",
       " 'value',\n",
       " 'publications',\n",
       " 'Centre',\n",
       " 'thousand',\n",
       " 'AG',\n",
       " 'ketones',\n",
       " 'medical',\n",
       " 'GET',\n",
       " 'farther',\n",
       " 'food',\n",
       " 'dictionarywyswyg',\n",
       " 'such',\n",
       " 'Lastly',\n",
       " 'rough',\n",
       " 'scholars',\n",
       " 'disk',\n",
       " 'knowledge',\n",
       " 'reporting',\n",
       " 'stalk',\n",
       " 'path',\n",
       " 'oils',\n",
       " 'July',\n",
       " 'nausea',\n",
       " 'Tunisian',\n",
       " 'relief',\n",
       " 'assemblyBut',\n",
       " 'USA',\n",
       " 'physics',\n",
       " 'Twitter',\n",
       " 'Wonderful',\n",
       " 'nose',\n",
       " 'disastrous',\n",
       " 'acronym',\n",
       " 'hesitated',\n",
       " 'damtihari',\n",
       " 'transfusions',\n",
       " '17',\n",
       " 'Gomti',\n",
       " 'mainly',\n",
       " 'fair',\n",
       " 'manufacture',\n",
       " 'fountains',\n",
       " 'Dharms',\n",
       " 'poverty',\n",
       " 'NGO',\n",
       " 'disorderly',\n",
       " 'economic',\n",
       " 'urine',\n",
       " 'UNESCO',\n",
       " 'Separation',\n",
       " 'Her',\n",
       " 'Handset',\n",
       " 'tomorrow',\n",
       " 'habitsproviding',\n",
       " 'earths',\n",
       " 'passengers',\n",
       " 'Puranic',\n",
       " 'bored',\n",
       " 'these',\n",
       " 'vast',\n",
       " 'behaviour',\n",
       " 'suggest',\n",
       " 'Although',\n",
       " 'soil',\n",
       " 'characteristic',\n",
       " 'ministers',\n",
       " 'inquiry',\n",
       " 'embarrassment',\n",
       " 'glasses',\n",
       " 'Poets',\n",
       " 'arbitrators',\n",
       " 'recording',\n",
       " 'Committing',\n",
       " '1757',\n",
       " 'All',\n",
       " 'trend',\n",
       " 'bali',\n",
       " 'board',\n",
       " 'absolutely',\n",
       " 'taxi',\n",
       " 'Teressas',\n",
       " 'Eye',\n",
       " 'Shak',\n",
       " 'issue',\n",
       " 'try',\n",
       " 'mere',\n",
       " 'discussions',\n",
       " 'subjects',\n",
       " 'Shukla',\n",
       " 'retrenchment',\n",
       " 'Verma',\n",
       " 'London',\n",
       " 'weaknesses',\n",
       " 'baby',\n",
       " 'Category1976',\n",
       " 'pilgrims',\n",
       " 'ghati',\n",
       " 'to',\n",
       " 'After',\n",
       " '1',\n",
       " 'madarsas',\n",
       " 'utterly',\n",
       " 'capability',\n",
       " 'puzzles',\n",
       " ...}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "df03a51a-d319-42ea-8f57-ae685d0624c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'संकोच',\n",
       " 'प्रेरणा',\n",
       " 'पासपोर्ट',\n",
       " 'एक',\n",
       " 'किशोरों',\n",
       " 'बेल',\n",
       " 'पडा',\n",
       " 'सांसदों',\n",
       " 'भविष्यवाणी',\n",
       " 'खंडन',\n",
       " 'उतारचढाव',\n",
       " 'अगस्त',\n",
       " 'आजाद',\n",
       " 'अलक्ष्य',\n",
       " 'मुझसे',\n",
       " 'मार्टिन',\n",
       " 'संख़्या',\n",
       " 'प्रतिभा',\n",
       " 'फैट',\n",
       " 'सुरक्षा',\n",
       " 'छिपा',\n",
       " 'नासा',\n",
       " 'नज़र',\n",
       " 'खुशी',\n",
       " 'स्त्रीपुरुषों',\n",
       " 'परिपत्र',\n",
       " 'सऋऊण्श्छ्ष्थान',\n",
       " 'अंडे',\n",
       " 'दोहरे',\n",
       " 'नियुक्त',\n",
       " 'आंखे',\n",
       " 'भगत',\n",
       " 'हिस्से',\n",
       " 'प्रकीर्णन',\n",
       " 'आँसुओं',\n",
       " 'विस्तृत',\n",
       " 'चुनौतियां',\n",
       " 'गहरे',\n",
       " 'स्थानस्थान',\n",
       " 'स्थापना',\n",
       " 'संसऋऊण्श्छ्ष्ऋतियों',\n",
       " 'मुयालय',\n",
       " 'जरिए',\n",
       " 'दवाई',\n",
       " 'शाक्यों',\n",
       " 'बजे',\n",
       " 'फांसी',\n",
       " 'दिलानेवाला',\n",
       " 'अम्पायर',\n",
       " 'बुद्ध',\n",
       " 'वाष्पशील',\n",
       " 'पहुँचाई।',\n",
       " 'प्रसन्न',\n",
       " 'कब्जे',\n",
       " 'आदिवराह',\n",
       " 'दोहराया',\n",
       " 'डेटिंग',\n",
       " 'देखे',\n",
       " 'स्वभाविक',\n",
       " 'फरवरी',\n",
       " 'अनोखे',\n",
       " 'संस्कृति',\n",
       " 'दस्ते',\n",
       " 'कैंसर',\n",
       " 'सीन',\n",
       " 'ड्रग्स',\n",
       " 'युगों',\n",
       " 'फारस',\n",
       " 'अर्नेस्ट',\n",
       " 'संकरण',\n",
       " 'करकों',\n",
       " 'एवं',\n",
       " 'ढली',\n",
       " 'अतिशय',\n",
       " 'बनाते',\n",
       " 'बढ़कर',\n",
       " 'कारोबार',\n",
       " 'हुलिया',\n",
       " 'चक्रवर्ती',\n",
       " 'कारखाने',\n",
       " 'मॉडलों',\n",
       " 'पांचवीं',\n",
       " 'एस',\n",
       " 'शीर्ष',\n",
       " 'समय',\n",
       " 'नियंत्रित',\n",
       " 'दावे',\n",
       " 'ग़्लूकोज',\n",
       " 'गैरहाजिर',\n",
       " 'भूख',\n",
       " 'उड़ाई।',\n",
       " 'ख़त्म',\n",
       " 'न्यायिक',\n",
       " 'बादामी',\n",
       " 'बर्बादी',\n",
       " 'पाएँ',\n",
       " 'फूट',\n",
       " 'ज्ञान',\n",
       " 'मान्यताओं',\n",
       " 'चुनी',\n",
       " 'आंदोलन',\n",
       " 'रजोनिवृत्ति',\n",
       " 'लाभदायक',\n",
       " 'कीजिए।',\n",
       " 'आया',\n",
       " 'मिस',\n",
       " 'नागरिको',\n",
       " 'उद्योग',\n",
       " 'योग़्यताओं',\n",
       " 'पाँच',\n",
       " 'अंग्रेज',\n",
       " 'सधा',\n",
       " 'पहनते',\n",
       " 'स्थित',\n",
       " 'बुरी',\n",
       " 'शास्त्रीय',\n",
       " 'वक्ता',\n",
       " 'सुना',\n",
       " 'मिलाकर',\n",
       " 'प्रास्थिति',\n",
       " 'कार्रवाई',\n",
       " 'किसानों',\n",
       " 'तीस',\n",
       " 'वकीलों',\n",
       " 'नियम',\n",
       " 'बाथरूम',\n",
       " 'नकुल',\n",
       " 'नेपाल',\n",
       " 'इसको',\n",
       " 'अलमारियों',\n",
       " 'बच्चो',\n",
       " 'घनीभूत',\n",
       " 'त्य्पोलोगिएस',\n",
       " 'अवशेष',\n",
       " 'थानों',\n",
       " 'परन्तु',\n",
       " 'भूल',\n",
       " '१५००',\n",
       " 'प्रचुर',\n",
       " 'भी।',\n",
       " 'कहानियां',\n",
       " 'चढ़',\n",
       " 'शोरा',\n",
       " 'बेटी',\n",
       " 'ह्यऔर',\n",
       " 'पाणिनि',\n",
       " 'परिवर्तन',\n",
       " 'अध्यक्षता',\n",
       " 'बेईमानी',\n",
       " 'चक्र',\n",
       " 'घटना',\n",
       " 'विजयनगर',\n",
       " 'सदी',\n",
       " 'तुली',\n",
       " 'निचले',\n",
       " 'जायेगा',\n",
       " 'इन्होंने',\n",
       " 'पुत्र',\n",
       " 'प्रेषण',\n",
       " 'मठाधीश',\n",
       " 'गोहत्या',\n",
       " 'मुद्रा',\n",
       " 'स्त्रोत',\n",
       " 'क्यूबा',\n",
       " 'घोटाले',\n",
       " 'मंडपों',\n",
       " 'गुजरना',\n",
       " 'सवच्छंद',\n",
       " 'बर्तनो',\n",
       " 'चंद्रकांता',\n",
       " 'एकांत',\n",
       " 'विविध',\n",
       " 'तोड़ी',\n",
       " 'प्रिय',\n",
       " 'समालोचना',\n",
       " 'थोड़ा',\n",
       " 'दिया',\n",
       " 'सुनाने',\n",
       " 'उपाध्यक्ष',\n",
       " 'वर्षगां',\n",
       " 'क्राउन',\n",
       " 'एकदूसरे',\n",
       " 'आपकी',\n",
       " 'दौड़ने',\n",
       " 'विषमपंखी',\n",
       " 'नीतियों',\n",
       " 'जाईये।',\n",
       " 'बालुकाश्म',\n",
       " 'धातुओं',\n",
       " 'चाही',\n",
       " 'पांडुलिपियों',\n",
       " 'बताए',\n",
       " 'महज',\n",
       " 'लगेंगे',\n",
       " 'स्मारक',\n",
       " 'त',\n",
       " 'लेखों',\n",
       " 'कर्तव्य',\n",
       " 'गांधी',\n",
       " 'आपराधिक',\n",
       " 'निस्संदेह',\n",
       " 'अभिलेख',\n",
       " 'याज्ञिक',\n",
       " 'जीतीजागती',\n",
       " 'बनी',\n",
       " 'वातावर्णजिम्मेदार',\n",
       " 'उपनिषद्',\n",
       " 'उपर',\n",
       " 'हैजब',\n",
       " 'जॉर्ज',\n",
       " 'सभ्यता',\n",
       " 'ब्राजील',\n",
       " 'दृढ़',\n",
       " 'योजनाओं',\n",
       " 'आना',\n",
       " 'पूँजी',\n",
       " 'बर्दाश्त',\n",
       " 'कमेन्न्ज',\n",
       " 'परिस्तिथि',\n",
       " 'मरहपट्टी',\n",
       " 'ईस्वी',\n",
       " 'करे।',\n",
       " 'दियें',\n",
       " 'कीजिएगा',\n",
       " 'शोषण',\n",
       " 'लाहौल',\n",
       " 'वापिस',\n",
       " 'सहित',\n",
       " 'कृति',\n",
       " 'जुड़ते',\n",
       " 'खिड़कियों',\n",
       " 'स्थपति',\n",
       " 'आंकड़ों',\n",
       " 'लोगो',\n",
       " '१९२',\n",
       " 'हज़रत',\n",
       " 'डी',\n",
       " 'लगे',\n",
       " 'करवाया',\n",
       " 'रेसोनेंस',\n",
       " 'सोलहवा',\n",
       " 'सजावट',\n",
       " 'हज़ारों',\n",
       " 'बुलाएँगे।',\n",
       " 'चाबियों',\n",
       " 'पत्र',\n",
       " 'खींची',\n",
       " 'सेवियों',\n",
       " 'मूंद',\n",
       " 'साफसुथरे',\n",
       " 'हत्यारे',\n",
       " 'हैइसे',\n",
       " 'फंचाई',\n",
       " 'लेगा।',\n",
       " 'जाएँगे।',\n",
       " 'असहयोग',\n",
       " 'बातें',\n",
       " 'लोकल',\n",
       " 'संजीवनी',\n",
       " 'कहां',\n",
       " 'इंडियाना',\n",
       " 'प्यार',\n",
       " 'कुध',\n",
       " 'मलबा',\n",
       " 'ढाई',\n",
       " 'मौजूदगी',\n",
       " 'हैं',\n",
       " 'कहती',\n",
       " 'सैर',\n",
       " 'संचित',\n",
       " 'मिनट',\n",
       " 'टीएचमॉर्गन',\n",
       " 'विदेशयात्रा',\n",
       " 'लंबी',\n",
       " 'कहते',\n",
       " 'प्रवाह',\n",
       " 'माफिया',\n",
       " 'रहस्योद्घाटन',\n",
       " 'योनियों',\n",
       " 'मंजूरी',\n",
       " 'दिया।',\n",
       " 'यमपुरी',\n",
       " 'पत्तों',\n",
       " 'तूफ़ान',\n",
       " 'मुझको',\n",
       " 'मुइक्त',\n",
       " 'श्रृंग',\n",
       " 'विस्थापित',\n",
       " 'लगाये',\n",
       " 'जाएगी।',\n",
       " 'कानपुर',\n",
       " 'किये',\n",
       " 'अस्पृश्यता',\n",
       " 'संभाल',\n",
       " 'विभिन्न',\n",
       " 'बढ़',\n",
       " 'लीजेंड्स',\n",
       " 'चौडाई',\n",
       " 'हिन्दी',\n",
       " 'कहीं',\n",
       " 'बेमतलब',\n",
       " 'कलाकृति',\n",
       " 'जजों',\n",
       " 'इंग्लिश',\n",
       " 'खड़े',\n",
       " 'साझीदारी',\n",
       " 'जाते',\n",
       " 'देती',\n",
       " 'इलके',\n",
       " 'प्रक्रियाओं',\n",
       " 'सांचे',\n",
       " 'मदरसों',\n",
       " 'युध',\n",
       " 'जमीनआसमान',\n",
       " 'रचकर',\n",
       " 'सालों',\n",
       " 'इतना',\n",
       " 'पत्नी',\n",
       " 'पुरावा',\n",
       " 'कुशासन',\n",
       " 'टुकडे़',\n",
       " 'सीमाओं',\n",
       " 'शेरा',\n",
       " 'राजद्रोह',\n",
       " 'छोर',\n",
       " 'मत।',\n",
       " 'आजीवन',\n",
       " 'दीं।',\n",
       " 'राज्यपाल',\n",
       " 'खनन',\n",
       " 'ज़ाहिर',\n",
       " 'प्रवास',\n",
       " 'घूरकर',\n",
       " 'मंचों',\n",
       " 'मेहताब',\n",
       " 'तस्वीरें',\n",
       " 'सीड़ियों',\n",
       " 'चित्रकला',\n",
       " 'जीजस',\n",
       " 'बार',\n",
       " 'कनफेडरेशन',\n",
       " 'इसमे',\n",
       " 'यान',\n",
       " 'सभा',\n",
       " 'भूलूँगा।',\n",
       " 'मैनें',\n",
       " 'रूपए',\n",
       " 'तीव्र',\n",
       " 'कीटोंस',\n",
       " 'उत्सुक',\n",
       " 'विधायक',\n",
       " 'संख्या',\n",
       " 'सपोर्ट',\n",
       " 'दसियों',\n",
       " 'अस्वीकार',\n",
       " 'रजिस्टर',\n",
       " 'वैदिक',\n",
       " 'बेसब्री',\n",
       " 'अमर',\n",
       " 'धुल',\n",
       " 'वो',\n",
       " 'अल्प',\n",
       " 'चलें',\n",
       " 'बाँटना',\n",
       " 'व्यास',\n",
       " 'रामायण',\n",
       " 'दिये',\n",
       " 'आजमगढ़',\n",
       " 'सीरियाई',\n",
       " 'बन्धन',\n",
       " 'काटते',\n",
       " 'ढंग',\n",
       " 'निकलने',\n",
       " 'आकाशीय',\n",
       " 'सिद्धार्थ',\n",
       " 'ऊतक',\n",
       " 'सकतीं',\n",
       " 'निगरानी',\n",
       " 'फेफड़ों',\n",
       " 'पैपीलैरिस',\n",
       " 'जाम',\n",
       " 'उनका',\n",
       " 'अखिल',\n",
       " 'टिकट',\n",
       " 'उपयोग',\n",
       " 'वि०',\n",
       " 'देर',\n",
       " 'विक्षनरी',\n",
       " 'पुनर्रचना',\n",
       " 'पीली',\n",
       " 'किरायेदारी',\n",
       " 'पिता',\n",
       " 'विफल',\n",
       " 'स्नातक',\n",
       " 'उठ',\n",
       " 'बदतरीन',\n",
       " 'कीर्तन',\n",
       " 'बहिया',\n",
       " 'घटनाक्रम',\n",
       " 'जितनी',\n",
       " 'जहाज़',\n",
       " 'प्रदायिनी',\n",
       " 'राजनैतिक',\n",
       " 'नीरवता',\n",
       " 'दिखाए',\n",
       " 'अन्याय',\n",
       " 'उन्मुक्तता',\n",
       " 'कवि',\n",
       " 'प्रभुसत्ता',\n",
       " 'सहदेव',\n",
       " 'सुनाया',\n",
       " 'पाठ्य',\n",
       " 'करीब',\n",
       " 'मूर्तियां',\n",
       " '१९७१',\n",
       " 'चुने',\n",
       " 'तिथि',\n",
       " 'पर',\n",
       " '२४०००',\n",
       " 'रहो',\n",
       " 'पंख',\n",
       " 'आज',\n",
       " 'हिस्सों',\n",
       " 'शिखरों',\n",
       " 'हैप्राचीन',\n",
       " 'पसलियां',\n",
       " 'दुःखी',\n",
       " 'मेट्रिक',\n",
       " 'लिखने',\n",
       " 'बकरियों',\n",
       " 'खोने',\n",
       " 'साइंसटिस्ट',\n",
       " 'तितली',\n",
       " 'प्रतिभाशाली',\n",
       " 'सीमा',\n",
       " 'वजूद',\n",
       " 'र्र्',\n",
       " 'विक्टोरिया',\n",
       " 'बहन',\n",
       " 'मग्नतट',\n",
       " 'पटरियां',\n",
       " 'आपैत्त',\n",
       " 'ओबेरॉय',\n",
       " 'रवैये',\n",
       " 'फारसी',\n",
       " 'खानऐखाना',\n",
       " 'कई',\n",
       " 'अपनाया',\n",
       " 'दमयन्ती',\n",
       " 'उत्सर्जन',\n",
       " 'बीतने',\n",
       " 'सेवक',\n",
       " 'रमेश',\n",
       " 'ब्रह्मचर्यतप',\n",
       " 'प्रयुक्त',\n",
       " 'कहेगा',\n",
       " 'वैज्ञानिक',\n",
       " 'बूढ़े',\n",
       " 'तट',\n",
       " 'ज़रूर',\n",
       " 'खोल',\n",
       " 'मृदंग',\n",
       " 'विकासक्रम',\n",
       " 'हैतो',\n",
       " 'सराहना',\n",
       " 'आरम्भ',\n",
       " 'जोड़ेने',\n",
       " 'गायिका',\n",
       " 'श्रृंखलाबद्ध',\n",
       " 'प्रकट',\n",
       " 'मीटर१४४००',\n",
       " 'दूसरे',\n",
       " 'आया।',\n",
       " '१९८७',\n",
       " 'नबी',\n",
       " 'रसायन',\n",
       " 'थाऔर',\n",
       " 'वाद्यों',\n",
       " 'इशारे',\n",
       " 'सीबीआइ',\n",
       " 'बनते',\n",
       " 'हुए',\n",
       " 'भूलती',\n",
       " 'हजारों',\n",
       " 'कौवे',\n",
       " 'धन्य',\n",
       " 'वफादार',\n",
       " 'जख़्मी',\n",
       " 'कही',\n",
       " 'मध्यकालीन',\n",
       " 'अवशिष्ट',\n",
       " 'लेने',\n",
       " 'गद्य',\n",
       " 'कायदे',\n",
       " 'ध्वस्त',\n",
       " 'तैयार',\n",
       " 'आतंकित',\n",
       " 'यूटीआइ',\n",
       " 'पूर्णतयः',\n",
       " 'महंगा',\n",
       " 'नतीजा',\n",
       " '१८५',\n",
       " 'सितंबर',\n",
       " 'व्यापारी',\n",
       " 'स्पर्धा',\n",
       " 'जिम्मेदारियों',\n",
       " 'टर्मिनस',\n",
       " 'अनपढ़',\n",
       " 'रक्तचाप',\n",
       " 'दुलार',\n",
       " 'रियासतों',\n",
       " 'सेक्स',\n",
       " 'लौटाना',\n",
       " 'यीशु',\n",
       " 'निर्देशित',\n",
       " 'पॉ',\n",
       " 'शिवभक़्त',\n",
       " 'पार',\n",
       " 'कुकुरमुत्तों',\n",
       " 'अवैध',\n",
       " 'सिरे',\n",
       " 'अपना',\n",
       " 'दस्तावेज',\n",
       " 'आंखों',\n",
       " 'घुसपै',\n",
       " 'राजधानी',\n",
       " 'पोंछना',\n",
       " 'हर्ष',\n",
       " 'देखेंगे',\n",
       " 'भिक्षु',\n",
       " 'ओर',\n",
       " 'दीवाने',\n",
       " 'जिन्होंने',\n",
       " 'टिका',\n",
       " 'मझ',\n",
       " 'लौटा',\n",
       " 'फोटो',\n",
       " 'दीवकंबर',\n",
       " 'खुलापन',\n",
       " 'गुजरता',\n",
       " 'खाड़ी',\n",
       " 'गंवाता',\n",
       " 'जर्मनी',\n",
       " 'करन',\n",
       " 'तोहफ़ा',\n",
       " 'हैकान',\n",
       " 'स्मिता',\n",
       " 'आग्रह',\n",
       " 'औसतन',\n",
       " 'योनियां',\n",
       " 'कोक',\n",
       " 'पुराना',\n",
       " 'जो',\n",
       " 'मतदान',\n",
       " 'विभाजित',\n",
       " 'जाये',\n",
       " 'आयताकार',\n",
       " 'आंच',\n",
       " 'सोचा',\n",
       " 'गरीब',\n",
       " 'ज़बरदस्त',\n",
       " 'पहने',\n",
       " 'छात्रों',\n",
       " 'ग्रह',\n",
       " 'बुलाई',\n",
       " 'अष्टांक',\n",
       " 'जाँचक',\n",
       " 'आपरेशनों',\n",
       " 'दृक्बिंदु',\n",
       " 'थेल्हीमर',\n",
       " 'छोडऋने',\n",
       " 'लम्बे',\n",
       " 'सदनों',\n",
       " 'सहारे',\n",
       " 'जटिलताओं',\n",
       " 'अभ्यास',\n",
       " 'सर्जरियों',\n",
       " 'मूर्तिकला',\n",
       " 'बताये',\n",
       " 'बनाने',\n",
       " 'आयुर्वेद',\n",
       " 'क्या',\n",
       " 'तुच्छ',\n",
       " 'पोर्स',\n",
       " 'देवता',\n",
       " 'जोशी',\n",
       " 'बदन',\n",
       " 'युवावस्था',\n",
       " 'इस्राइली',\n",
       " 'हिसाब',\n",
       " 'सौभाग्य',\n",
       " 'होड',\n",
       " 'महान',\n",
       " 'हिरासत',\n",
       " 'प्रभात',\n",
       " 'इसऋऊण्श्छ्ष्तेमाल',\n",
       " 'न्योता',\n",
       " 'राजपूत',\n",
       " 'खैरात',\n",
       " 'परिभाषाएँ',\n",
       " 'पीकर',\n",
       " 'लौटाती',\n",
       " 'रोड़ी',\n",
       " 'अम्ल',\n",
       " 'डेवलपिन्ग',\n",
       " 'छंदों',\n",
       " 'संग्राम',\n",
       " 'पाँचवी',\n",
       " 'चौरस',\n",
       " 'कपड़ै',\n",
       " 'निषिद्ध',\n",
       " 'जाऊँगा।',\n",
       " 'बदरूद्दीन',\n",
       " 'फैला',\n",
       " 'दीं',\n",
       " 'संदर्भ',\n",
       " 'तरल',\n",
       " 'आओगे',\n",
       " 'अवसर',\n",
       " 'लगाया',\n",
       " 'निर्दोशन',\n",
       " 'बाएं',\n",
       " 'उल्लास',\n",
       " 'ष्र्',\n",
       " 'प्रापऋऊण्श्छ्ष्त',\n",
       " 'धरोहरों',\n",
       " 'प्रतीक्षा',\n",
       " 'उन्होंने',\n",
       " 'ग्रीनहाउस',\n",
       " 'टीका',\n",
       " 'विशेष',\n",
       " 'उद्देश्यों',\n",
       " 'जनसांख्यिकी',\n",
       " 'उपलध',\n",
       " 'सदृश्य',\n",
       " 'छोडकर',\n",
       " 'चीनी',\n",
       " 'गाएं',\n",
       " 'लाईं।',\n",
       " 'उड़ते',\n",
       " 'उपदेश',\n",
       " 'हवाई',\n",
       " 'पटियाँ',\n",
       " 'पड़ते',\n",
       " 'निर्वाचकों',\n",
       " 'बढ़ती',\n",
       " 'केंद्रीय',\n",
       " 'अली',\n",
       " 'इमेजिंग',\n",
       " 'सवारी',\n",
       " 'बढऋआना',\n",
       " 'मारे',\n",
       " 'भगवद्',\n",
       " 'टिके',\n",
       " 'जचती',\n",
       " 'प्रदूषक',\n",
       " 'अनुताप',\n",
       " 'निति',\n",
       " 'मेगस्थनीज',\n",
       " 'अफ़गान',\n",
       " 'माक्र्सवादी',\n",
       " 'शोधकर्ताओं',\n",
       " 'टल',\n",
       " 'स्थावर',\n",
       " 'एग्रीगेटर्स',\n",
       " 'हैमबर्गर',\n",
       " 'भाजपा',\n",
       " 'सीनेट',\n",
       " 'प्राच्य',\n",
       " 'साम्राज्यवाद',\n",
       " 'महिषमर्दिनी',\n",
       " 'रेत',\n",
       " 'टास्क',\n",
       " 'व्याख़्यान',\n",
       " 'घंटी',\n",
       " 'फौज',\n",
       " 'कांस्य',\n",
       " 'थामैंने',\n",
       " 'प्रशन',\n",
       " 'अठारह',\n",
       " 'बज़ूका',\n",
       " 'कटी',\n",
       " 'लेकर',\n",
       " 'लंदन',\n",
       " 'पेंच',\n",
       " 'जोड़ेते',\n",
       " 'वर्चस्व',\n",
       " 'कौनसी',\n",
       " 'प्रवेशद्वार',\n",
       " 'मनाया',\n",
       " 'नई',\n",
       " 'खतम',\n",
       " '७८७५११८००',\n",
       " 'बनारस',\n",
       " 'खनिज',\n",
       " 'पोषित',\n",
       " 'क्रिया',\n",
       " 'कृष्क',\n",
       " 'रिक़्तियां',\n",
       " 'पुछेंगे',\n",
       " 'सेवाओं',\n",
       " 'उल्टियां',\n",
       " 'गंगा',\n",
       " 'चंद्रबाबू',\n",
       " 'पाटन',\n",
       " 'प्रिवी',\n",
       " 'मांस',\n",
       " 'सफ़र',\n",
       " 'सम्मान',\n",
       " 'श्रेणीभारत',\n",
       " 'पशुबलि',\n",
       " 'मंगलेश',\n",
       " 'धरम',\n",
       " 'विशाल',\n",
       " 'गीली',\n",
       " 'मान',\n",
       " 'दिए',\n",
       " 'ऊंचाई',\n",
       " 'चेहरे',\n",
       " 'शहरी',\n",
       " 'पाता',\n",
       " 'भांति',\n",
       " 'रास्ता',\n",
       " 'इमारतों',\n",
       " 'सेवन',\n",
       " 'चिडिया',\n",
       " 'पड़ेता',\n",
       " 'कर्मचारी',\n",
       " 'हैंइस',\n",
       " 'पुन',\n",
       " 'महंगी',\n",
       " 'प्रस्तावित',\n",
       " 'परामर्शी',\n",
       " 'क्षेत्रों',\n",
       " 'नीति',\n",
       " 'वियात',\n",
       " 'लांगमैन',\n",
       " 'तुम्हारी',\n",
       " 'स्थिर',\n",
       " 'कमाई',\n",
       " 'लखनऊ',\n",
       " 'मुसलमानसंस्कृति',\n",
       " 'हथियार',\n",
       " 'मृत्यु',\n",
       " 'बहाना',\n",
       " 'उद्येश्य',\n",
       " 'सर्जन',\n",
       " 'राजपूताना',\n",
       " 'बनानी',\n",
       " 'चलाया',\n",
       " 'असंख़्य',\n",
       " '३६००',\n",
       " 'शामिल',\n",
       " 'अधिकारों',\n",
       " 'अंदर',\n",
       " 'दयालु',\n",
       " 'प्वाइंट',\n",
       " 'तसल्ली',\n",
       " 'लिंक्स',\n",
       " 'यहां',\n",
       " 'मोर्चा',\n",
       " 'सामाऋक',\n",
       " 'रामानुज',\n",
       " 'एकएक',\n",
       " 'टांगों',\n",
       " 'व्यक़्तिपरक',\n",
       " 'भूलना',\n",
       " 'वृद्ध',\n",
       " 'केन्द्र',\n",
       " 'कौस्ट्स',\n",
       " 'रेशमा',\n",
       " 'गुरुंग',\n",
       " 'साइकिल',\n",
       " 'पंजाब',\n",
       " 'शिशु',\n",
       " 'प्रदुषण',\n",
       " 'भावात्मक',\n",
       " 'खींची।',\n",
       " 'माईने',\n",
       " 'जिलों',\n",
       " 'केतु',\n",
       " 'यानी',\n",
       " 'खोलो।',\n",
       " 'आधीन',\n",
       " 'चाहिए।',\n",
       " 'विस्फोट',\n",
       " 'रे',\n",
       " 'सीखा',\n",
       " 'तराजू',\n",
       " 'वीर्यपात',\n",
       " 'संपर्क',\n",
       " 'आरसु',\n",
       " 'डबा',\n",
       " 'पीठ',\n",
       " 'अब्बास',\n",
       " 'अभिनय',\n",
       " 'तमिलनाडू',\n",
       " 'काटो।',\n",
       " 'भारती',\n",
       " 'आपातकाल',\n",
       " 'हँसी',\n",
       " 'मैक्सिको',\n",
       " 'संख्यात्मक',\n",
       " 'नज़रों',\n",
       " 'भी',\n",
       " 'बेगुनाह',\n",
       " 'उपलइधयों',\n",
       " 'उसने',\n",
       " 'काफी',\n",
       " 'पक्ष',\n",
       " 'गुणों',\n",
       " 'फेंकने',\n",
       " 'स्वायत्तता',\n",
       " 'बनने',\n",
       " 'बेरोजगारी',\n",
       " 'बर्ताव',\n",
       " '१९००',\n",
       " 'निष्णात',\n",
       " 'अपडेट',\n",
       " 'नल',\n",
       " 'आहार',\n",
       " 'भुला',\n",
       " 'अधिकता',\n",
       " 'पेंशन',\n",
       " 'राजसी',\n",
       " 'संगीत',\n",
       " 'लुढ़काता',\n",
       " 'डाउनलोड',\n",
       " 'इंडस्ट्रियल',\n",
       " 'हस्तिनपुर',\n",
       " 'प्रभावशाली',\n",
       " 'खुला',\n",
       " 'चुकी',\n",
       " 'रखने',\n",
       " 'नवीनतम',\n",
       " '५५६१',\n",
       " 'कहलाती',\n",
       " 'आउट',\n",
       " 'मापदंड',\n",
       " 'पुर्तगालियों',\n",
       " 'कुन्हा',\n",
       " 'ब्रौंज',\n",
       " 'राजय',\n",
       " 'स्थायी',\n",
       " 'दोस्तों',\n",
       " 'फुंसियाँ',\n",
       " 'ज़िंदगी',\n",
       " 'पुनरार्वन',\n",
       " 'शासन',\n",
       " 'गुना',\n",
       " 'अक्सर',\n",
       " 'मिलें',\n",
       " 'शुरू',\n",
       " 'हो',\n",
       " 'उतऋऊण्श्छ्ष्पादन',\n",
       " 'खांसी',\n",
       " 'लाते',\n",
       " 'वृहद',\n",
       " 'गड़बड़ी',\n",
       " 'चिह्र',\n",
       " 'डिप्टेरा',\n",
       " 'छोड',\n",
       " 'तेजी',\n",
       " 'चला',\n",
       " 'फ्रीक्वेंसी',\n",
       " 'कुत्तों',\n",
       " '९९',\n",
       " 'कॅरिअर',\n",
       " 'व्रत',\n",
       " 'सुविधाओं',\n",
       " 'लाना',\n",
       " 'पुरोहितों',\n",
       " 'जनरल',\n",
       " 'जेब',\n",
       " 'व्यक़्तिगत',\n",
       " 'रचनात्मक',\n",
       " 'बदला',\n",
       " 'सहस्त्रों',\n",
       " 'चुकताऊँगा।',\n",
       " 'विकसित',\n",
       " 'परिणाम',\n",
       " 'बढ़ता',\n",
       " 'गए।',\n",
       " 'उत्कीर्णनों',\n",
       " 'बैठा',\n",
       " 'फूलती',\n",
       " 'मध्यवर्गीय',\n",
       " 'मुकदमे',\n",
       " 'ज़रा',\n",
       " 'जिसमें',\n",
       " 'प्रश्नों',\n",
       " 'टाल',\n",
       " 'शिश्नच्छद',\n",
       " 'कृषि',\n",
       " 'सफेद',\n",
       " 'पाया।',\n",
       " 'आरेख',\n",
       " 'कोशिकीय',\n",
       " 'कार्यावधि',\n",
       " 'लाजिमी',\n",
       " 'एंड',\n",
       " 'स्वर',\n",
       " 'दरवाज़े',\n",
       " 'खेत',\n",
       " 'पाबंदी',\n",
       " 'झुर्रियां',\n",
       " 'मुलाकात',\n",
       " 'इसपर',\n",
       " 'शाक्ति',\n",
       " 'फिल्मोद्योग',\n",
       " 'वसीयत',\n",
       " 'खुफिया',\n",
       " 'खुदा',\n",
       " 'राजी',\n",
       " 'स्टॉक',\n",
       " 'सैडल',\n",
       " 'ऋस',\n",
       " 'हेलमेट',\n",
       " 'अलैहि',\n",
       " 'कलाकार',\n",
       " 'अच्छे',\n",
       " 'उनकी',\n",
       " 'फेडरेशन',\n",
       " 'दुनियुआ',\n",
       " 'उदघोषणा',\n",
       " 'सेनानायक',\n",
       " 'महेन्द्र',\n",
       " 'स्टीव',\n",
       " 'किताबों',\n",
       " 'खेरी',\n",
       " 'दिनों',\n",
       " 'पश्चात',\n",
       " 'प्रस्तुत',\n",
       " 'बी',\n",
       " 'फीसों',\n",
       " 'छोड़',\n",
       " 'स्थापित',\n",
       " 'आए।',\n",
       " 'वही',\n",
       " 'कंप्यूटर',\n",
       " 'दाहक',\n",
       " 'तलाशने',\n",
       " 'शिव',\n",
       " 'धारावाहिक',\n",
       " 'सकने',\n",
       " 'निरंकुश',\n",
       " 'अमाप',\n",
       " 'तालाब',\n",
       " 'क़िताब',\n",
       " 'क्षेत्र',\n",
       " 'सूक्ष्मजीवों',\n",
       " 'रहकर',\n",
       " 'सिर्फ',\n",
       " 'ढोरलकी',\n",
       " 'आपका',\n",
       " 'सुभाष',\n",
       " 'गलत',\n",
       " 'जून',\n",
       " 'ज़्यादा',\n",
       " 'उल्लिखित',\n",
       " 'सुदामा',\n",
       " 'मायने',\n",
       " 'ग्रंथ',\n",
       " 'बजाया',\n",
       " 'जीस्पॉट',\n",
       " 'काबू',\n",
       " '१६१३',\n",
       " 'पढ़ने',\n",
       " 'असर',\n",
       " 'अतीत।',\n",
       " 'आमतौर',\n",
       " 'नंदी',\n",
       " 'उतारने',\n",
       " 'अंग्रेजी',\n",
       " 'बढ़ावा',\n",
       " 'खाद्य',\n",
       " 'रिस',\n",
       " 'प्रबंधन',\n",
       " 'कमर',\n",
       " 'चित्रित',\n",
       " 'दीवानएखास',\n",
       " 'चलो',\n",
       " 'सोनी',\n",
       " 'हां',\n",
       " 'मुखियाओं',\n",
       " 'प्रस्तुति',\n",
       " 'चरम',\n",
       " 'गए',\n",
       " 'फीस',\n",
       " 'होगे',\n",
       " 'महत्त्व',\n",
       " 'प्रारंभिक',\n",
       " 'धूम्रपान',\n",
       " 'पुराण',\n",
       " 'चिड़ियां',\n",
       " 'छापा',\n",
       " 'बच्चेबच्ची',\n",
       " 'योनि',\n",
       " 'प्रमेह',\n",
       " 'धैर्य',\n",
       " ...}"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "634e6e32-8e6d-4bfb-af8d-9fd66dca3d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english vocabulary size =  7457\n",
      "hindi vocabulary size =  7768\n"
     ]
    }
   ],
   "source": [
    "print(\"english vocabulary size = \", len(eng_words))\n",
    "print(\"hindi vocabulary size = \", len(hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d6c3fefc-d4e5-43a7-8bf9-4eab0bb28d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['length_eng_sentence']=new_data['english'].apply(lambda x:len(x.split(\" \")))\n",
    "new_data['length_hin_sentence']=new_data['hindi'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "41126059-e753-46d2-b9b1-61ef3800bf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>ZealWednesday</td>\n",
       "      <td>start_ जोश बुद्धवार _end</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5381</th>\n",
       "      <td>Kathmandu court ancient templegroup of Palaces...</td>\n",
       "      <td>start_ यूनेस्को की आठ सांस्कृतिक विश्व धरोहरों...</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>Tell me the truth</td>\n",
       "      <td>start_ मुझे सच्चाई बताओ। _end</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>the typical way that ordinary matter does</td>\n",
       "      <td>start_ जैसी सामान्य पदार्थ करते हैं _end</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>The train is ten minutes behind today</td>\n",
       "      <td>start_ आज ट्रेन दस मिनट लेट है। _end</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                english  \\\n",
       "9323                                      ZealWednesday   \n",
       "5381  Kathmandu court ancient templegroup of Palaces...   \n",
       "336                                   Tell me the truth   \n",
       "7755          the typical way that ordinary matter does   \n",
       "2203              The train is ten minutes behind today   \n",
       "\n",
       "                                                  hindi  length_eng_sentence  \\\n",
       "9323                           start_ जोश बुद्धवार _end                    1   \n",
       "5381  start_ यूनेस्को की आठ सांस्कृतिक विश्व धरोहरों...                   20   \n",
       "336                       start_ मुझे सच्चाई बताओ। _end                    4   \n",
       "7755           start_ जैसी सामान्य पदार्थ करते हैं _end                    7   \n",
       "2203               start_ आज ट्रेन दस मिनट लेट है। _end                    7   \n",
       "\n",
       "      length_hin_sentence  \n",
       "9323                    4  \n",
       "5381                   21  \n",
       "336                     5  \n",
       "7755                    7  \n",
       "2203                    8  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "3d20dd5b-5aae-4f14-aefd-3aa7dc04a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of english language =  121\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of english language = \", max(new_data['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "ccc8a7ed-f1d9-4389-9a6b-b94440a621bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of hindi language =  141\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of hindi language = \", max(new_data['length_hin_sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506eb89f-8fe1-4414-9b59-5673e28e7f13",
   "metadata": {},
   "source": [
    "### Model Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c955640b-5666-4416-91d7-81d1d3c9522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_src = max(new_data['length_eng_sentence'])\n",
    "max_len_tar = max(new_data['length_hin_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "eb6c1660-0250-4235-9e5d-79eb4ee3c3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(eng_words))\n",
    "target_words = sorted(list(hindi_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "49ecd349-aeda-4baa-9631-545062ba729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7457, 7768)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens = len(eng_words)\n",
    "num_decoder_tokens = len(hindi_words)\n",
    "\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c3a4ebc4-6049-478e-8c4a-f26aff41614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens += 1 \n",
    "num_encoder_tokens += 1\n",
    "#zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "82fab692-0f4f-4459-b3ad-43ecdb1a65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "3eac199c-029d-41cc-84d5-7fb831a68cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6fe57091-9e1d-44b5-9593-8364e255157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2fdf345a-d720-42ce-b602-0f947f3dad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = shuffle(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "1f6f649a-243b-4fcf-8b17-334121615e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>The devout who have set up ashrams by the doze...</td>\n",
       "      <td>start_ जिन साधुओं ने इस पर्वतीय इलके में करीब ...</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>All of my kids want to learn French</td>\n",
       "      <td>start_ मेरे सभी बच्चें फ़्रेंच सीखना चाहते हैं...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2226</th>\n",
       "      <td>He embezzled the money from his office</td>\n",
       "      <td>start_ उसने अपने दफ़तर के पैसों को गबन किया। _end</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>done in collaboration with Danish artist Soren...</td>\n",
       "      <td>start_ जो डेनिश सहयोगी कलाकार सोरेन पोर्स के स...</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5138</th>\n",
       "      <td>It is doubtful if Vajpayee can return Wahid s ...</td>\n",
       "      <td>start_ अब इसमें संदेह है कि वाजपेयी अपने सरकार...</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                english  \\\n",
       "6724  The devout who have set up ashrams by the doze...   \n",
       "2020                All of my kids want to learn French   \n",
       "2226             He embezzled the money from his office   \n",
       "5403  done in collaboration with Danish artist Soren...   \n",
       "5138  It is doubtful if Vajpayee can return Wahid s ...   \n",
       "\n",
       "                                                  hindi  length_eng_sentence  \\\n",
       "6724  start_ जिन साधुओं ने इस पर्वतीय इलके में करीब ...                   31   \n",
       "2020  start_ मेरे सभी बच्चें फ़्रेंच सीखना चाहते हैं...                    8   \n",
       "2226  start_ उसने अपने दफ़तर के पैसों को गबन किया। _end                    7   \n",
       "5403  start_ जो डेनिश सहयोगी कलाकार सोरेन पोर्स के स...                    8   \n",
       "5138  start_ अब इसमें संदेह है कि वाजपेयी अपने सरकार...                   15   \n",
       "\n",
       "      length_hin_sentence  \n",
       "6724                   32  \n",
       "2020                    9  \n",
       "2226                   10  \n",
       "5403                   13  \n",
       "5138                   20  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ae81856d-70ce-4894-a052-f265c9bc2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = new_data['english'], new_data['hindi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "aac68d78-9232-4784-899d-f372851fa28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.series.Series, pandas.core.series.Series)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x), type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0e274b25-7e8b-40a6-82a7-cd2e614534eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e29c5feb-909e-4570-a8e9-3f2371ad729d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1995,)\n",
      "(499,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ac153869-099e-4684-9d07-ebaaf375b18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1995,)\n",
      "(499,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "69c35cd6-5575-43f3-bdf0-953040bda6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data1(X, y, max_len_src, max_len_tar, num_decoder_tokens, input_token_index, target_token_index):\n",
    "    ''' Preprocess the data for encoder-decoder model '''\n",
    "    encoder_input_data = np.zeros((len(X), max_len_src), dtype='float16')\n",
    "    decoder_input_data = np.zeros((len(y), max_len_tar), dtype='float16')\n",
    "    decoder_target_data = np.zeros((len(y), max_len_tar, num_decoder_tokens), dtype='float16')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(X, y)):\n",
    "        for t, word in enumerate(input_text.split()):\n",
    "            if word in input_token_index:\n",
    "                encoder_input_data[i, t] = input_token_index[word]  # encoder input seq\n",
    "            else:\n",
    "                encoder_input_data[i, t] = input_token_index['<UNK>']  # handle out-of-vocabulary words\n",
    "            \n",
    "        for t, word in enumerate(target_text.split()):\n",
    "            if word in target_token_index:\n",
    "                decoder_input_data[i, t] = target_token_index[word]  # decoder input seq\n",
    "                if t > 0:\n",
    "                    decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            else:\n",
    "                decoder_input_data[i, t] = target_token_index['<UNK>']  # handle out-of-vocabulary words\n",
    "    \n",
    "    return [encoder_input_data, decoder_input_data], decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "b6ac3e75-be1b-499f-ba0d-53780c1c6cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_train_new, x_train_decoder_input], y_train_new = preprocess_data1(x_train, y_train, max_len_src, max_len_tar, num_decoder_tokens, input_token_index, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c34a32eb-fcd1-4248-906b-c1633e5194be",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x_test_new, x_test_decoder_input], y_test_new = preprocess_data1(x_test, y_test, max_len_src, max_len_tar, num_decoder_tokens, input_token_index, target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ba539683-47c2-4804-805a-d8c3e705138b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1991., 2346., 6536., ...,    0.,    0.,    0.],\n",
       "        [ 911., 4720., 2048., ...,    0.,    0.,    0.],\n",
       "        [1854., 7228., 3230., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [1780., 5328., 6868., ...,    0.,    0.,    0.],\n",
       "        [1071.,  564., 3000., ...,    0.,    0.,    0.],\n",
       "        [1638.,    0.,    0., ...,    0.,    0.,    0.]], dtype=float16),\n",
       " 1618                      We are sorry we cannot help you\n",
       " 907                              He knows a lot of people\n",
       " 7112    The virtuous cycle of rising stock prices  whi...\n",
       " 4540    The share of consumer electronics was to decli...\n",
       " 7731                                  is about the future\n",
       "                               ...                        \n",
       " 4609          When the headlines rolled what happened was\n",
       " 5401    Their food habits are simple and change from r...\n",
       " 6952                             Structure of the Council\n",
       " 6189    Kalpana Chaval completed her primary education...\n",
       " 3314                                      SanginiSaturday\n",
       " Name: english, Length: 1995, dtype: object)"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_new, x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "07715d52-44d3-417d-9816-708a1de753bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9e11b-c33a-4cef-8285-6b09f420bc23",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "12cc217c-7d49-45e5-bee4-32d47c45b27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "a97350b9-7a86-489b-af59-005db8a50fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decoder with encoder-states as initial states\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "467b8657-e834-423c-99b5-242013598cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "50571eca-9050-443d-8f2d-946df089d2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=CategoricalCrossentropy(from_logits=False), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b08590f8-4096-4f38-80a4-1d4bcf01cb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,237,400</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,330,700</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)]        │                 │ not_equal_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                 │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>),       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">721,200</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
       "│                               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)] │                 │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>], lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7769</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,338,469</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │       \u001b[38;5;34m2,237,400\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ not_equal_6 (\u001b[38;5;33mNotEqual\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)         │       \u001b[38;5;34m2,330,700\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │         \u001b[38;5;34m721,200\u001b[0m │ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)]        │                 │ not_equal_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)                 │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m),       │         \u001b[38;5;34m721,200\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
       "│                               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)] │                 │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m], lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m] │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7769\u001b[0m)        │       \u001b[38;5;34m2,338,469\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]               │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,348,969</span> (31.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,348,969\u001b[0m (31.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,348,969</span> (31.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,348,969\u001b[0m (31.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "8034becf-c4ae-4392-89a7-f0404c8633f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "0e072dbe-c9c9-441c-b8e6-af6ec444ae34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step - accuracy: 0.0060 - loss: 8.1738 - val_accuracy: 0.0040 - val_loss: 6.7417\n",
      "Epoch 2/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 3s/step - accuracy: 0.0068 - loss: 6.6219 - val_accuracy: 0.0071 - val_loss: 6.6464\n",
      "Epoch 3/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.0075 - loss: 6.5042 - val_accuracy: 0.0096 - val_loss: 6.5945\n",
      "Epoch 4/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.0090 - loss: 6.3927 - val_accuracy: 0.0098 - val_loss: 6.5677\n",
      "Epoch 5/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.0093 - loss: 6.3590 - val_accuracy: 0.0097 - val_loss: 6.5304\n",
      "Epoch 6/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 3s/step - accuracy: 0.0093 - loss: 6.3201 - val_accuracy: 0.0094 - val_loss: 6.5222\n",
      "Epoch 7/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.0094 - loss: 6.2863 - val_accuracy: 0.0098 - val_loss: 6.5129\n",
      "Epoch 8/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 3s/step - accuracy: 0.0097 - loss: 6.2838 - val_accuracy: 0.0091 - val_loss: 6.5034\n",
      "Epoch 9/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 2s/step - accuracy: 0.0095 - loss: 6.2186 - val_accuracy: 0.0098 - val_loss: 6.5120\n",
      "Epoch 10/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3s/step - accuracy: 0.0098 - loss: 6.2155 - val_accuracy: 0.0085 - val_loss: 6.5021\n",
      "Epoch 11/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 3s/step - accuracy: 0.0094 - loss: 6.1695 - val_accuracy: 0.0102 - val_loss: 6.4756\n",
      "Epoch 12/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 3s/step - accuracy: 0.0099 - loss: 6.2003 - val_accuracy: 0.0097 - val_loss: 6.4666\n",
      "Epoch 13/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 2s/step - accuracy: 0.0096 - loss: 6.1109 - val_accuracy: 0.0104 - val_loss: 6.4581\n",
      "Epoch 14/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.0099 - loss: 6.0643 - val_accuracy: 0.0093 - val_loss: 6.4356\n",
      "Epoch 15/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.0100 - loss: 6.0796 - val_accuracy: 0.0092 - val_loss: 6.4808\n",
      "Epoch 16/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.0101 - loss: 6.0320 - val_accuracy: 0.0111 - val_loss: 6.4193\n",
      "Epoch 17/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 3s/step - accuracy: 0.0105 - loss: 5.9861 - val_accuracy: 0.0112 - val_loss: 6.4017\n",
      "Epoch 18/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 3s/step - accuracy: 0.0108 - loss: 5.9953 - val_accuracy: 0.0111 - val_loss: 6.4000\n",
      "Epoch 19/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 4s/step - accuracy: 0.0107 - loss: 5.9563 - val_accuracy: 0.0114 - val_loss: 6.4227\n",
      "Epoch 20/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.0107 - loss: 5.8985 - val_accuracy: 0.0108 - val_loss: 6.3935\n",
      "Epoch 21/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 4s/step - accuracy: 0.0108 - loss: 5.8941 - val_accuracy: 0.0107 - val_loss: 6.3929\n",
      "Epoch 22/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step - accuracy: 0.0109 - loss: 5.8876 - val_accuracy: 0.0114 - val_loss: 6.3462\n",
      "Epoch 23/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 4s/step - accuracy: 0.0109 - loss: 5.8388 - val_accuracy: 0.0118 - val_loss: 6.3354\n",
      "Epoch 24/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 3s/step - accuracy: 0.0110 - loss: 5.8182 - val_accuracy: 0.0114 - val_loss: 6.3436\n",
      "Epoch 25/25\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 3s/step - accuracy: 0.0108 - loss: 5.7980 - val_accuracy: 0.0104 - val_loss: 6.3485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x196e2b27250>"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    [x_train_new, x_train_decoder_input], y_train_new,\n",
    "    batch_size=64,\n",
    "    epochs=25,\n",
    "    validation_data=([x_test_new, x_test_decoder_input], y_test_new)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "1f8055ef-753a-47c9-8338-83bc911aa3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('translation_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f156d85b-c961-47ba-ac6a-a2f1df20ba82",
   "metadata": {},
   "source": [
    "### Testing the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f3db7e82-937f-44cd-b3b7-bd2750587abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "f7597268-b734-454f-a4c6-cda9b9569716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = target_token_index['start_']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        if (sampled_char == '_end' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "9d20176a-250b-42ba-997d-3bc7ef5b3669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = x_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_len_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_len_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_len_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "192ba1e1-5e0a-4f6c-ba85-f5c32acb407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generate_batch(x_train, y_train, batch_size = 1)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "951add46-3de1-4cf4-a0fe-db6e516535e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1618                      We are sorry we cannot help you\n",
       " 907                              He knows a lot of people\n",
       " 7112    The virtuous cycle of rising stock prices  whi...\n",
       " 4540    The share of consumer electronics was to decli...\n",
       " 7731                                  is about the future\n",
       "                               ...                        \n",
       " 4609          When the headlines rolled what happened was\n",
       " 5401    Their food habits are simple and change from r...\n",
       " 6952                             Structure of the Council\n",
       " 6189    Kalpana Chaval completed her primary education...\n",
       " 3314                                      SanginiSaturday\n",
       " Name: english, Length: 1995, dtype: object,\n",
       " array([[1991., 2346., 6536., ...,    0.,    0.,    0.],\n",
       "        [ 911., 4720., 2048., ...,    0.,    0.,    0.],\n",
       "        [1854., 7228., 3230., ...,    0.,    0.,    0.],\n",
       "        ...,\n",
       "        [1780., 5328., 6868., ...,    0.,    0.,    0.],\n",
       "        [1071.,  564., 3000., ...,    0.,    0.,    0.],\n",
       "        [1638.,    0.,    0., ...,    0.,    0.,    0.]], dtype=float16))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a0996365-5d68-432b-aa28-1eaa111be737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 752ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Input English sentence: We are sorry we cannot help you\n",
      "Actual Hindi Translation:  माफ़ कीजिए पर हम आपकी मदद नहीं कर सकते। \n",
      "Predicted Hindi Translation:  मैं में में में \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', x_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c18d18-954a-4413-b8eb-94a34598aaa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
